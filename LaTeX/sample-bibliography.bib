%Export citations from http://dblp.uni-trier.de/
%If websites do not have a author, set the title as author.

@article{paulmann2011there,
	title={Is there an advantage for recognizing multi-modal emotional stimuli?},
	author={Paulmann, Silke and Pell, Marc D},
	journal={Motivation and Emotion},
	volume={35},
	number={2},
	pages={192--201},
	year={2011},
	publisher={Springer}
}

@inproceedings{poria2017context,
	title={Context-dependent sentiment analysis in user-generated videos},
	author={Poria, Soujanya and Cambria, Erik and Hazarika, Devamanyu and Majumder, Navonil and Zadeh, Amir and Morency, Louis-Philippe},
	booktitle={Proceedings of the 55th annual meeting of the association for computational linguistics (volume 1: Long papers)},
	pages={873--883},
	year={2017}
}

@article{shenoy2020multilogue,
	title={Multilogue-net: A context aware rnn for multi-modal emotion detection and sentiment analysis in conversation},
	author={Shenoy, Aman and Sardana, Ashish},
	journal={arXiv preprint arXiv:2002.08267},
	year={2020}
}

@inproceedings{yakaew2021multimodal,
	title={Multimodal Sentiment Analysis on Video Streams using Lightweight Deep Neural Networks.},
	author={Yakaew, Atitaya and Dailey, Matthew N and Racharak, Teeradaj},
	booktitle={ICPRAM},
	pages={442--451},
	year={2021}
}

@article{zadeh2016mosi,
	title={Mosi: multimodal corpus of sentiment intensity and subjectivity analysis in online opinion videos},
	author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},
	journal={arXiv preprint arXiv:1606.06259},
	year={2016}
}

@inproceedings{zadeh2018multimodal,
	title={Multimodal language analysis in the wild: Cmu-mosei dataset and interpretable dynamic fusion graph},
	author={Zadeh, AmirAli Bagher and Liang, Paul Pu and Poria, Soujanya and Cambria, Erik and Morency, Louis-Philippe},
	booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	pages={2236--2246},
	year={2018}
}

@article{liang2022msctd,
	title={Msctd: A multimodal sentiment chat translation dataset},
	author={Liang, Yunlong and Meng, Fandong and Xu, Jinan and Chen, Yufeng and Zhou, Jie},
	journal={arXiv preprint arXiv:2202.13645},
	year={2022}
}

@article{liu2019roberta,
	title={Roberta: A robustly optimized bert pretraining approach},
	author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	journal={arXiv preprint arXiv:1907.11692},
	year={2019}
}

@article{meng2020openvidial,
	title={Openvidial: A large-scale, open-domain dialogue dataset with visual contexts},
	author={Meng, Yuxian and Wang, Shuhe and Han, Qinghong and Sun, Xiaofei and Wu, Fei and Yan, Rui and Li, Jiwei},
	journal={arXiv preprint arXiv:2012.15015},
	year={2020}
}

@article{zhang2016joint,
	title={Joint face detection and alignment using multitask cascaded convolutional networks},
	author={Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
	journal={IEEE signal processing letters},
	volume={23},
	number={10},
	pages={1499--1503},
	year={2016},
	publisher={IEEE}
}

@inproceedings{kazemi2014one,
	title={One millisecond face alignment with an ensemble of regression trees},
	author={Kazemi, Vahid and Sullivan, Josephine},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={1867--1874},
	year={2014}
}

@article{busso2008iemocap,
	title={IEMOCAP: Interactive emotional dyadic motion capture database},
	author={Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N and Lee, Sungbok and Narayanan, Shrikanth S},
	journal={Language resources and evaluation},
	volume={42},
	number={4},
	pages={335--359},
	year={2008},
	publisher={Springer}
}

@inproceedings{nojavanasghari2016emoreact,
	title={Emoreact: a multimodal approach and dataset for recognizing emotional responses in children},
	author={Nojavanasghari, Behnaz and Baltru{\v{s}}aitis, Tadas and Hughes, Charles E and Morency, Louis-Philippe},
	booktitle={Proceedings of the 18th acm international conference on multimodal interaction},
	pages={137--144},
	year={2016}
}
                  
@inproceedings{ahuja2020no,
	title={No Gestures Left Behind: Learning Relationships between Spoken Language and Freeform Gestures},
	author={Ahuja, Chaitanya and Lee, Dong Won and Ishii, Ryo and Morency, Louis-Philippe},
	booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings},
	pages={1884--1895},
	year={2020}
}
                   
@inproceedings{ahuja2020style,
	title={Style Transfer for Co-Speech Gesture Animation: A Multi-Speaker Conditional-Mixture Approach},
	author={Chaitanya Ahuja and Dong Won Lee and Yukiko I. Nakano and Louis-Philippe Morency},
	venue = {European Conference on Computer Vision (ECCV)}
	year={2020},
	month = {August},
	year = {2020},
	url={https://arxiv.org/abs/2007.12553}
}

@inproceedings{ginosar2019learning,
	title={Learning individual styles of conversational gesture},
	author={Ginosar, Shiry and Bar, Amir and Kohavi, Gefen and Chan, Caroline and Owens, Andrew and Malik, Jitendra},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={3497--3506},
	year={2019}
}

@article{savchenko2022classifying,
	title={Classifying emotions and engagement in online learning based on a single facial expression recognition neural network},
	author={Savchenko, Andrey V and Savchenko, Lyudmila V and Makarov, Ilya},
	journal={IEEE Transactions on Affective Computing},
	year={2022},
	publisher={IEEE}
}

@article{akhtar2019multi,
	title={Multi-task learning for multi-modal emotion recognition and sentiment analysis},
	author={Akhtar, Md Shad and Chauhan, Dushyant Singh and Ghosal, Deepanway and Poria, Soujanya and Ekbal, Asif and Bhattacharyya, Pushpak},
	journal={arXiv preprint arXiv:1905.05812},
	year={2019}
}

@inproceedings{xiao2018simple,
	title={Simple baselines for human pose estimation and tracking},
	author={Xiao, Bin and Wu, Haiping and Wei, Yichen},
	booktitle={Proceedings of the European conference on computer vision (ECCV)},
	pages={466--481},
	year={2018}
}