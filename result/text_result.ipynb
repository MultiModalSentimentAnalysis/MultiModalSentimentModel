{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(str(BASE_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from extractors.text_extractors.text_extractor import TextEmbeddingExtractor\n",
    "\n",
    "embedding_extractor = TextEmbeddingExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3331\n",
      "3331\n",
      "3331\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "features_path = BASE_DIR / \"data/saved_features\"\n",
    "real_indexes = torch.load(features_path / f\"real_indexes_{SPLIT}.pt\").tolist()\n",
    "print(len(real_indexes))\n",
    "\n",
    "with open(BASE_DIR / \"data\" / f\"english_{SPLIT}.txt\") as f:\n",
    "    all_sentences = [l.strip() for l in f.readlines()]\n",
    "    sentences = [all_sentences[i] for i in real_indexes]\n",
    "# sentences = sentences[:n]\n",
    "print(len(sentences))\n",
    "with open(BASE_DIR / \"data\" / f\"sentiment_{SPLIT}.txt\") as f:\n",
    "    all_sentiments = [int(l.strip()) for l in f.readlines()]\n",
    "    sentiments = [all_sentiments[i] for i in real_indexes]\n",
    "# sentiments = sentiments[:n]\n",
    "print(len(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = embedding_extractor.get_labels(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.42389672770939657}\n",
      "{'precision': array([0.30227828, 0.77892919, 0.7414966 ])}\n",
      "{'precision': 0.6075680206384703}\n",
      "{'precision': 0.42389672770939657}\n",
      "{'precision': 0.6460379450717734}\n",
      "{'f1': array([0.44921403, 0.4382896 , 0.33641975])}\n",
      "{'f1': 0.4079744604145013}\n",
      "{'f1': 0.42389672770939657}\n",
      "{'f1': 0.41043375439932483}\n",
      "{'recall': array([0.87411765, 0.30493577, 0.21756487])}\n",
      "{'recall': 0.4655394282429057}\n",
      "{'recall': 0.42389672770939657}\n",
      "{'recall': 0.42389672770939657}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "def convert_label(label):\n",
    "    if label == \"NEU\":\n",
    "        return 0\n",
    "    elif label == \"NEG\":\n",
    "        return 1\n",
    "    elif label == \"POS\":\n",
    "        return 2\n",
    "\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "precision_macro = evaluate.load(\"precision\")\n",
    "precision_micro = evaluate.load(\"precision\")\n",
    "precision_weighted = evaluate.load(\"precision\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "f1_macro = evaluate.load(\"f1\")\n",
    "f1_micro = evaluate.load(\"f1\")\n",
    "f1_weighted = evaluate.load(\"f1\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "recall_macro = evaluate.load(\"recall\")\n",
    "recall_micro = evaluate.load(\"recall\")\n",
    "recall_weighted = evaluate.load(\"recall\")\n",
    "\n",
    "for index, result in enumerate(results):\n",
    "    predicted_label = convert_label(result[\"label\"])\n",
    "    accuracy.add(predictions=predicted_label, references=sentiments[index])\n",
    "    precision.add(predictions=predicted_label, references=sentiments[index])\n",
    "    precision_macro.add(predictions=predicted_label, references=sentiments[index])\n",
    "    precision_micro.add(predictions=predicted_label, references=sentiments[index])\n",
    "    precision_weighted.add(predictions=predicted_label, references=sentiments[index])\n",
    "    f1.add(predictions=predicted_label, references=sentiments[index])\n",
    "    f1_macro.add(predictions=predicted_label, references=sentiments[index])\n",
    "    f1_micro.add(predictions=predicted_label, references=sentiments[index])\n",
    "    f1_weighted.add(predictions=predicted_label, references=sentiments[index])\n",
    "    recall.add(predictions=predicted_label, references=sentiments[index])\n",
    "    recall_macro.add(predictions=predicted_label, references=sentiments[index])\n",
    "    recall_micro.add(predictions=predicted_label, references=sentiments[index])\n",
    "    recall_weighted.add(predictions=predicted_label, references=sentiments[index])\n",
    "\n",
    "print(accuracy.compute())\n",
    "print(precision.compute(average=None))\n",
    "print(precision_macro.compute(average=\"macro\"))\n",
    "print(precision_micro.compute(average=\"micro\"))\n",
    "print(precision_weighted.compute(average=\"weighted\"))\n",
    "print(f1.compute(average=None))\n",
    "print(f1_macro.compute(average=\"macro\"))\n",
    "print(f1_micro.compute(average=\"micro\"))\n",
    "print(f1_weighted.compute(average=\"weighted\"))\n",
    "print(recall.compute(average=None))\n",
    "print(recall_macro.compute(average=\"macro\"))\n",
    "print(recall_micro.compute(average=\"micro\"))\n",
    "print(recall_weighted.compute(average=\"weighted\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "17880c9d61fb44f60131b7c571e7dba3ecf129f794c4b04264e3510409962454"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
